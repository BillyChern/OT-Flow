# OT-flow/train_flow_matching.py

import torch
import torch.optim as optim
import torch.nn.functional as F
import yaml
import os
import datetime
import numpy as np

from vae_model import VAE # To load VAE architecture if needed for z1 directly
from dataset_loader import get_data_loader # To get z1 (target latents)
from ot_model import OTMapSolver # To get z0 (source latents from OT map output)
from flow_matching_model import VelocityFieldModel

def train_flow_matcher(config_path="configs/vae_config.yaml"):
    # --- Configuration --- #
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # --- General, VAE, OT, and Flow Matching Configs --- #
    vae_conf = config
    ot_solver_save_dir_config = config.get('ot_solver_save_dir')
    fm_conf = config.get('flow_matching_params', {})
    flow_model_save_path = config.get('flow_model_save_path', "OT-flow/saved_models/flow_model_default.pth")
    vae_encoder_path = config.get('vae_encoder_path') # Needed if we regenerate z1 on the fly

    # Create directories for logs and saved models
    timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    log_dir = f"OT-flow/logs/flow_matching_training_{timestamp}"
    # Model save path is directly taken from config for FM
    os.makedirs(log_dir, exist_ok=True)
    os.makedirs(os.path.dirname(flow_model_save_path), exist_ok=True)

    # --- Load OTMapSolver (contains target latents h_P which are our z1) --- #
    if not ot_solver_save_dir_config:
        print("Error: 'ot_solver_save_dir' not specified in config.")
        return
    
    ot_solver_final_state_path = os.path.join(ot_solver_save_dir_config, "ot_solver_state_final.pth")

    if not os.path.exists(ot_solver_final_state_path):
        print(f"Error: OTMapSolver final state '{ot_solver_final_state_path}' not found. Train OT map first.")
        # For a dry run, we could create a dummy OT solver state
        print("Attempting to create a DUMMY OT solver state for dry run... This will not yield meaningful results.")
        os.makedirs(ot_solver_save_dir_config, exist_ok=True) # Ensure dir exists for dummy
        # dummy_ot_dir = os.path.dirname(ot_solver_path or "OT-flow/saved_models/dummy_ot.pth")
        # os.makedirs(dummy_ot_dir, exist_ok=True)
        # dummy_ot_path = os.path.join(dummy_ot_dir, "dummy_ot_solver_state.pth")
        
        num_dummy_latents = 1000 # Number of samples for the dummy h_P
        dummy_h_P = torch.randn(num_dummy_latents, vae_conf['latent_dim'], dtype=torch.float32)
        dummy_d_h = torch.zeros(num_dummy_latents, 1, dtype=torch.float64)
        dummy_ot_state = {
            'h_P': dummy_h_P, 
            'd_h': dummy_d_h, 
            'dim_noise': vae_conf['latent_dim'], 
            'params': config.get('ot_map_params', {})
        }
        torch.save(dummy_ot_state, ot_solver_final_state_path)
        # ot_solver_path = dummy_ot_path
        print(f"Using DUMMY OT solver state from: {ot_solver_final_state_path}")
        # return # Exit if no real OT solver
        
    ot_solver = OTMapSolver.load_solver_state(ot_solver_final_state_path, device=device)
    # z1_target_latents are the h_P from the OT solver (VAE encoder outputs)
    # These are float64 on device from ot_solver.h_P. Convert to float32 for FM training.
    z1_target_latents = ot_solver.h_P.float().to(device) # Shape: (num_dataset_samples, latent_dim)
    print(f"Loaded z1 target latents (from VAE via OT solver): {z1_target_latents.shape}")

    # --- Data Source for z0 (output of OT map) --- #
    # z0 will be generated by passing N(0,I) noise through ot_solver.map_noise()
    # The dimension of noise matches latent_dim.

    # --- Flow Matching Model and Optimizer --- #
    flow_model = VelocityFieldModel(
        latent_dim=vae_conf['latent_dim'],
        time_embed_dim=fm_conf.get('time_embed_dim', 128),
        hidden_dims=fm_conf.get('hidden_dims', [512, 512, 512])
    ).to(device)

    optimizer = optim.Adam(flow_model.parameters(), lr=float(fm_conf.get('learning_rate', 1e-4)))

    batch_size = fm_conf.get('batch_size', 256)
    num_epochs = fm_conf.get('epochs', 100)
    save_freq = fm_conf.get('save_epoch_freq', 10)

    print("Starting Flow Matching training...")
    for epoch in range(num_epochs):
        flow_model.train()
        total_epoch_loss = 0
        
        # Calculate number of batches based on the size of z1_target_latents
        num_z1_samples = z1_target_latents.shape[0]
        num_batches = (num_z1_samples + batch_size - 1) // batch_size

        # Shuffle z1_target_latents each epoch by shuffling indices
        permuted_indices = torch.randperm(num_z1_samples, device=device)

        for batch_idx in range(num_batches):
            # --- Prepare Batch Data --- # 
            # Get a batch of z1 (target latents)
            start_idx = batch_idx * batch_size
            end_idx = min((batch_idx + 1) * batch_size, num_z1_samples)
            actual_batch_size = end_idx - start_idx
            if actual_batch_size == 0: continue

            batch_indices = permuted_indices[start_idx:end_idx]
            z1_batch = z1_target_latents[batch_indices]
            
            # Sample z0 (source latents from OT map output)
            # Sample N(0,I) noise for the OT map
            noise_for_ot = torch.randn(actual_batch_size, vae_conf['latent_dim'], dtype=torch.float32, device=device)
            z0_batch = ot_solver.map_noise(noise_for_ot) # Already on device and float32

            # Sample time t ~ U[0,1]
            t_batch = torch.rand(actual_batch_size, 1, device=device)

            # --- Flow Matching Loss Calculation --- #
            # Construct z_t = (1-t)z0 + tz1 (linear interpolation)
            zt_batch = (1 - t_batch) * z0_batch + t_batch * z1_batch
            
            # Target vector field u_t = z1 - z0
            ut_batch_target = z1_batch - z0_batch
            
            # Predicted vector field v_psi(z_t, t)
            vt_batch_predicted = flow_model(zt_batch, t_batch.squeeze(1)) # Squeeze t for model
            
            loss = F.mse_loss(vt_batch_predicted, ut_batch_target)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            total_epoch_loss += loss.item() * actual_batch_size

            if batch_idx % 100 == 0: # Log every 100 batches
                print(f"Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx}/{num_batches}] Loss: {loss.item():.6f}")
        
        avg_epoch_loss = total_epoch_loss / num_z1_samples
        print(f"====> Epoch {epoch+1} completed. Average Loss: {avg_epoch_loss:.6f}")

        # Save model checkpoint
        if (epoch + 1) % save_freq == 0 or epoch == num_epochs - 1:
            # torch.save(flow_model.state_dict(), flow_model_save_path)
            # print(f"Saved Flow Matching model checkpoint to {flow_model_save_path} (epoch {epoch+1})")
            # If you want epoch-specific saves:
            current_save_path = flow_model_save_path.replace(".pth", f"_epoch_{epoch+1}.pth")
            torch.save(flow_model.state_dict(), current_save_path)
            print(f"Saved Flow Matching model checkpoint to {current_save_path}")


    print("Flow Matching training finished.")
    # Final save is handled by epoch condition above

if __name__ == "__main__":
    config_f_path = "OT-flow/configs/vae_config.yaml"

    try:
        with open(config_f_path, 'r') as f_read:
            temp_config_data = yaml.safe_load(f_read)
    except FileNotFoundError:
        print(f"Config file {config_f_path} not found. Cannot run flow matching training test.")
        exit()

    # Modify config for a quick test run
    original_fm_epochs = temp_config_data.get('flow_matching_params', {}).get('epochs', 100)
    temp_config_data.setdefault('flow_matching_params', {})['epochs'] = 3 # Quick test epochs
    temp_config_data.setdefault('flow_matching_params', {})['save_epoch_freq'] = 1
    temp_config_data.setdefault('flow_matching_params', {})['batch_size'] = 32 # Smaller batch for faster iteration
    
    # Ensure OT solver path exists or point to a dummy for test
    temp_ot_save_dir = temp_config_data.get('ot_solver_save_dir', "OT-flow/saved_models/ot_solver_test_run_dummy/")
    temp_config_data['ot_solver_save_dir'] = temp_ot_save_dir # ensure it uses the test dir
    temp_ot_final_state_path = os.path.join(temp_ot_save_dir, "ot_solver_state_final.pth")
    
    if not os.path.exists(temp_ot_final_state_path):
        # If the dummy final state for the test doesn't exist, ensure the test logic can still run
        # by effectively triggering the dummy creation within train_flow_matcher if needed.
        # This part is tricky because train_flow_matcher expects the file, 
        # but its own dummy creation might kick in. For safety, ensure the path points to where a dummy would be.
        temp_config_data['ot_solver_save_dir'] = temp_ot_save_dir # This should point to the directory
    
    temp_fm_model_path = "OT-flow/saved_models/flow_model_test_run.pth"
    temp_config_data['flow_model_save_path'] = temp_fm_model_path

    temp_config_file_for_fm_test = "OT-flow/configs/temp_fm_test_config.yaml"
    with open(temp_config_file_for_fm_test, 'w') as f_temp_write:
        yaml.dump(temp_config_data, f_temp_write, sort_keys=False)

    print(f"--- Running Flow Matching Training Test with reduced epochs using config {temp_config_file_for_fm_test} ---")
    try:
        train_flow_matcher(config_path=temp_config_file_for_fm_test)
    except Exception as e:
        print(f"An error occurred during Flow Matching training test: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if os.path.exists(temp_config_file_for_fm_test):
            os.remove(temp_config_file_for_fm_test)
        # Clean up dummy OT solver state if it was created by this script implicitly
        # (The OT training script itself would create a more specific dummy if run)
        dummy_ot_dir_check = temp_config_data['ot_solver_save_dir']
        if "ot_solver_test_run_dummy" in dummy_ot_dir_check or ("ot_solver_test_run" in dummy_ot_dir_check and os.path.exists(dummy_ot_dir_check)):
            # Only remove if this script was likely the one to create it through the dummy logic in train_flow_matcher
            print(f"Cleaning up dummy OT solver directory: {dummy_ot_dir_check}")
            import shutil
            shutil.rmtree(dummy_ot_dir_check, ignore_errors=True)
        if os.path.exists(temp_fm_model_path): # Clean up test model
            os.remove(temp_fm_model_path)

